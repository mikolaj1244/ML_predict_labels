# H1 Predicting Lables For Unbalanced Data Set: Project Overview
* Predicted lables values of large (3749, 10000) imbalanced (1:3374, -1:375) data set (F2 socre ~ 0.93)
* Optimized SVC, KNN, and Extra Trees Classifier using hyperopt-sklearn to reach the best model.
# H2 Code and Resources Used:
* **Python Version:** 3.8
* pandas, numpy, sklearn, matplotlib, seaborn, joblib
* hyperopt-sklearn https://github.com/hyperopt/hyperopt-sklearn
* Markdown-Cheatsheet https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet
* machinelearningmastery https://machinelearningmastery.com/framework-for-imbalanced-classification-projects/
# H2 EDA

(https://github.com/mikolaj1244/ML_predict_labels/tree/Miko%C5%82aj_Marcinkiewicz/plots/desc_plot.png "Describe")
(https://github.com/mikolaj1244/ML_predict_labels/tree/Miko%C5%82aj_Marcinkiewicz/plots/value_counts.png "value_counts 1") (https://github.com/mikolaj1244/ML_predict_labels/tree/Miko%C5%82aj_Marcinkiewicz/plots/pca_tesne_ss.png  "pca_tesne_standard_scaler 1")
(https://github.com/mikolaj1244/ML_predict_labels/tree/Miko%C5%82aj_Marcinkiewicz/plots/pca_tesne.png  "pca_tesne 1")


# H2 Model Building
First, we splited the data into train and tests sets with a test size of 10%.
We few different models and evaluated them using F2 socre. We chose F2 socre because it is ...
The models we have traied:
* SVC
* KNN
* Extra Trees Classifier
* Dummy Classiier(strategy='uniform') - for the baseline
*
*

# H2 Modle Preformence
* 
*
*
*
*
# H2 Predicted lables 
